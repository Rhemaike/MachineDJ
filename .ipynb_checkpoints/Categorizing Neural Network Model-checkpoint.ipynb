{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE NEURAL NETWORK TO CARTIGORIZE MUSIC\n",
    "#### author: Rhema Ike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "DATA_DIR = \"DataSets\"\n",
    "file_name = \"SongDataSetLess_4000.xlsx\"\n",
    "\n",
    "file_name = os.path.join(DATA_DIR, file_name)\n",
    "\n",
    "df = pd.read_excel(file_name)\n",
    "df.drop([\"name\",\"artist\"], axis=1,inplace=True)\n",
    "\n",
    "\n",
    "PLAYLIST_LEN = 1000\n",
    "target = ([1]* PLAYLIST_LEN) + ([2]* PLAYLIST_LEN) + ([4]* PLAYLIST_LEN) + ([4]* PLAYLIST_LEN)\n",
    "target_df = pd.DataFrame(target, columns=[\"target\"])\n",
    "\n",
    "df = pd.concat([df,target_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.868</td>\n",
       "      <td>-25.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>62.372</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.974</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.805</td>\n",
       "      <td>-27.330</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>136.106</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.991</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>2</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.857</td>\n",
       "      <td>-25.511</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>123.869</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.992</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>1</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.928</td>\n",
       "      <td>-28.498</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>69.897</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.846</td>\n",
       "      <td>-22.356</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>179.921</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.980</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      key  liveness  instrumentalness  loudness  mode  speechiness    tempo  \\\n",
       "3995    0     0.119             0.868   -25.880     0       0.0352   62.372   \n",
       "3996    0     0.110             0.805   -27.330     1       0.0376  136.106   \n",
       "3997    2     0.111             0.857   -25.511     1       0.0407  123.869   \n",
       "3998    1     0.109             0.928   -28.498     1       0.0432   69.897   \n",
       "3999    0     0.115             0.846   -22.356     0       0.0520  179.921   \n",
       "\n",
       "      valence  danceability  energy  acousticness  target  \n",
       "3995    0.123         0.200  0.0132         0.974       4  \n",
       "3996    0.130         0.222  0.0654         0.991       4  \n",
       "3997    0.276         0.270  0.0751         0.992       4  \n",
       "3998    0.590         0.284  0.0308         0.989       4  \n",
       "3999    0.199         0.260  0.0166         0.980       4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_df(df):\n",
    "    for col in df.columns:\n",
    "        if col in [\"key\", \"loudness\", \"tempo\"]:\n",
    "            df[col] = df[col] = preproc.scale(df[col].values)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    data = []\n",
    "    for row in df.values:\n",
    "        data.append([np.array(row[:-1]),row[-1]])\n",
    "        \n",
    "    random.shuffle(data)\n",
    "        \n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for X,y in data:\n",
    "        X_data.append(X)\n",
    "        y_data.append(y-1)\n",
    "    \n",
    "        \n",
    "    return np.array(X_data), np.array(y_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = preproc_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(70, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(70, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(70, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(4, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 0s 124us/sample - loss: 0.7417 - accuracy: 0.6500 - val_loss: 0.5126 - val_accuracy: 0.7525\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 0.4609 - accuracy: 0.8025 - val_loss: 0.4448 - val_accuracy: 0.8037\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 0.4149 - accuracy: 0.8303 - val_loss: 0.4318 - val_accuracy: 0.8163\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 0.3978 - accuracy: 0.8363 - val_loss: 0.3996 - val_accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 0.3713 - accuracy: 0.8544 - val_loss: 0.4403 - val_accuracy: 0.8275\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 0s 34us/sample - loss: 0.3629 - accuracy: 0.8534 - val_loss: 0.3937 - val_accuracy: 0.8475\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 0.3526 - accuracy: 0.8591 - val_loss: 0.4044 - val_accuracy: 0.8388\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 0.3465 - accuracy: 0.8647 - val_loss: 0.3796 - val_accuracy: 0.8475\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 0s 33us/sample - loss: 0.3408 - accuracy: 0.8631 - val_loss: 0.3833 - val_accuracy: 0.8450\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 0s 32us/sample - loss: 0.3355 - accuracy: 0.8666 - val_loss: 0.3834 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c3f266f048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\roike\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models\\simp_neural_net\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "file_name = \"simp_neural_net\"\n",
    "\n",
    "file_name = os.path.join(MODEL_DIR, file_name)\n",
    "model.save(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
