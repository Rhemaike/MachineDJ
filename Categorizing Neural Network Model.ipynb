{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE NEURAL NETWORK TO CARTIGORIZE MUSIC\n",
    "#### author: Rhema Ike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"MUSIC_CAT_NN_1\"\n",
    "dir_name = os.path.join(\"logs\", NAME)\n",
    "tensorboard = Tensorboard = TensorBoard(log_dir=dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "DATA_DIR = \"DataSets\"\n",
    "file_name = \"SongDataSetLess_4000.xlsx\"\n",
    "\n",
    "file_name = os.path.join(DATA_DIR, file_name)\n",
    "\n",
    "df = pd.read_excel(file_name)\n",
    "df.drop([\"name\",\"artist\"], axis=1,inplace=True)\n",
    "\n",
    "\n",
    "PLAYLIST_LEN = 1000\n",
    "target = ([1]* PLAYLIST_LEN) + ([2]* PLAYLIST_LEN) + ([3]* PLAYLIST_LEN) + ([4]* PLAYLIST_LEN)\n",
    "target_df = pd.DataFrame(target, columns=[\"target\"])\n",
    "\n",
    "df = pd.concat([df,target_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                   Believer\n",
       "artist              Crazy Fluke\n",
       "key                          11\n",
       "liveness                   0.22\n",
       "instrumentalness          0.874\n",
       "loudness                 -7.407\n",
       "mode                          0\n",
       "speechiness              0.0813\n",
       "tempo                   122.988\n",
       "valence                   0.684\n",
       "danceability              0.723\n",
       "energy                    0.869\n",
       "acousticness           0.000404\n",
       "target                        3\n",
       "Name: 2400, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing as preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_df(df):\n",
    "    for col in df.columns:\n",
    "        if col in [\"key\", \"loudness\", \"tempo\"]:\n",
    "            df[col] = preproc.scale(df[col].values)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    data = []\n",
    "    for row in df.values:\n",
    "        data.append([np.array(row[:-1]),row[-1]])\n",
    "        \n",
    "    random.shuffle(data)\n",
    "        \n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for X,y in data:\n",
    "        X_data.append(X)\n",
    "        y_data.append(y-1)\n",
    "    \n",
    "        \n",
    "    return np.array(X_data), np.array(y_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = preproc_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(60, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(60, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(4, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 1s 172us/sample - loss: 0.8435 - accuracy: 0.6803 - val_loss: 0.5521 - val_accuracy: 0.7775\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 0s 50us/sample - loss: 0.4970 - accuracy: 0.8019 - val_loss: 0.4662 - val_accuracy: 0.8075\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 0s 60us/sample - loss: 0.4414 - accuracy: 0.8256 - val_loss: 0.4265 - val_accuracy: 0.8300\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 0s 58us/sample - loss: 0.4081 - accuracy: 0.8416 - val_loss: 0.4137 - val_accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 0s 60us/sample - loss: 0.3886 - accuracy: 0.8456 - val_loss: 0.4041 - val_accuracy: 0.8462\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 0s 50us/sample - loss: 0.3775 - accuracy: 0.8522 - val_loss: 0.4404 - val_accuracy: 0.8263\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 0s 52us/sample - loss: 0.3711 - accuracy: 0.8569 - val_loss: 0.4002 - val_accuracy: 0.8512\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 0s 53us/sample - loss: 0.3609 - accuracy: 0.8591 - val_loss: 0.4132 - val_accuracy: 0.8375\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 0s 51us/sample - loss: 0.3587 - accuracy: 0.8578 - val_loss: 0.3960 - val_accuracy: 0.8450\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 0s 64us/sample - loss: 0.3477 - accuracy: 0.8634 - val_loss: 0.3931 - val_accuracy: 0.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c386d213c8>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=10,validation_split=0.2,  callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\simp_neural_net_2l_60n\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "file_name = \"simp_neural_net_2l_60n\"\n",
    "\n",
    "file_name = os.path.join(MODEL_DIR, file_name)\n",
    "model.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Model\n",
    "Song_categorizer_model = tf.keras.models.load_model(file_name)\n",
    "predictions = Song_categorizer_model.predict(X)\n",
    "# np.array(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file='model.png', show_shapes=False, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
